## ⚡ Advanced LLM-Powered Application using LangChain

This project showcases an advanced LLM-based application using **LangChain** to integrate multiple language models and embedding providers including **OpenAI**, **Claude (Anthropic)**, **Google Gemini AI**, and **Hugging Face**. It supports **dynamic prompt handling**, **multi-model querying**, and **flexible output generation** based on user input or business logic. Embedding models are used to power semantic search and retrieval-based tasks.

---

### 🚀 Key Features

* 🔗 **Multi-LLM integration**:
  OpenAI (GPT-4), Claude, Google Gemini, and Hugging Face (local and API-based)

* 🧠 **Chat-based workflows** using `ChatOpenAI`, `ChatGoogle`, `ChatAnthropic`, and `ChatHuggingFace`

* 🧩 **Modular architecture** using LangChain's prompt templates, chains, and tools

* 📡 **Real-time data fetching**, user input processing, and SQL query generation via LLMs

* 💬 **Natural language to SQL conversion** using integrated language models

* 🧠 **Embeddings integration**:

  * OpenAI embeddings (`OpenAIEmbeddings`)
  * Hugging Face embeddings (`HuggingFaceEmbeddings`)
  * Supports both local and hosted models

* 🔐 **Secure API key handling** via `.env` for all providers

---

### 🛠 Built Using

* Python
* LangChain
* OpenAI API
* Claude (Anthropic) API
* Google Gemini API
* Hugging Face Inference API & Local Models

---

### 🧰 Tech Stack

* **Python**
* **LangChain**
* **OpenAI GPT**
* **Anthropic Claude**
* **Google Gemini**
* **Hugging Face** (Local & API models)
* **Hugging Face & OpenAI Embeddings**