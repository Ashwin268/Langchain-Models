## âš¡ Advanced LLM-Powered Application using LangChain

This project showcases an advanced LLM-based application using **LangChain** to integrate multiple language models and embedding providers including **OpenAI**, **Claude (Anthropic)**, **Google Gemini AI**, and **Hugging Face**. It supports **dynamic prompt handling**, **multi-model querying**, and **flexible output generation** based on user input or business logic. Embedding models are used to power semantic search and retrieval-based tasks.

---

### ğŸš€ Key Features

* ğŸ”— **Multi-LLM integration**:
  OpenAI (GPT-4), Claude, Google Gemini, and Hugging Face (local and API-based)

* ğŸ§  **Chat-based workflows** using `ChatOpenAI`, `ChatGoogle`, `ChatAnthropic`, and `ChatHuggingFace`

* ğŸ§© **Modular architecture** using LangChain's prompt templates, chains, and tools

* ğŸ“¡ **Real-time data fetching**, user input processing, and SQL query generation via LLMs

* ğŸ’¬ **Natural language to SQL conversion** using integrated language models

* ğŸ§  **Embeddings integration**:

  * OpenAI embeddings (`OpenAIEmbeddings`)
  * Hugging Face embeddings (`HuggingFaceEmbeddings`)
  * Supports both local and hosted models

* ğŸ” **Secure API key handling** via `.env` for all providers

---

### ğŸ›  Built Using

* Python
* LangChain
* OpenAI API
* Claude (Anthropic) API
* Google Gemini API
* Hugging Face Inference API & Local Models

---

### ğŸ§° Tech Stack

* **Python**
* **LangChain**
* **OpenAI GPT**
* **Anthropic Claude**
* **Google Gemini**
* **Hugging Face** (Local & API models)
* **Hugging Face & OpenAI Embeddings**